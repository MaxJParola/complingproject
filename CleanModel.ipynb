{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer   # “Term Frequency times Inverse Document Frequency”\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB       # Multinomial Naive Bayes, supposedly goes well with the data from the transformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\maxjp\\\\PycharmProjects\\\\complingproject\\\\MasterDataFile.csv')      # to read the training data into working memory\n",
    "df['feature'] = df['feature'].replace(to_replace='<.*>', value='', regex=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['feature'],   # Test-Train Split function\n",
    "                                                    df['target'],\n",
    "                                                    train_size = 0.8,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=14\n",
    "\n",
    "vect = CountVectorizer(min_df=1,          # Minimum Document Frequency\n",
    "                       ngram_range=(1, 2),   # unigrams to bigrams\n",
    "                       stop_words='english',   # stopwords\n",
    "                       lowercase =False,\n",
    "                       binary = True\n",
    "                       ).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "X_train_vectorized_tfidf = TfidfTransformer().fit_transform(X_train_vectorized) # or X_train_dense\n",
    "X_test_vectorized_tfidf = TfidfTransformer().fit_transform(X_test_vectorized) # or X_test_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVCParam_Grid = ({'penalty': ['l2'], 'loss': ['squared_hinge'], 'dual': [True, False], 'C': [1, 100, 1000, 10000], \n",
    "                  'multi_class': ['ovr', 'crammer_singer'], 'max_iter': [1000, 2000, 8000]},\n",
    "                  {'penalty': ['l2'], 'loss': ['hinge', 'squared_hinge'], 'dual': [True], 'C': [1, 100, 1000, 10000], \n",
    "                  'multi_class': ['ovr', 'crammer_singer'], 'max_iter': [1000, 2000, 8000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC()\n",
    "clf = GridSearchCV(lsvc, LSVCParam_Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n     verbose=0),\n       fit_params=None, iid=True, n_jobs=1,\n       param_grid=({'penalty': ['l2'], 'loss': ['squared_hinge'], 'dual': [True, False], 'C': [1, 100, 1000, 10000], 'multi_class': ['ovr', 'crammer_singer'], 'max_iter': [1000, 2000, 8000]}, {'penalty': ['l2'], 'loss': ['hinge', 'squared_hinge'], 'dual': [True], 'C': [1, 100, 1000, 10000], 'multi_class': ['ovr', 'crammer_singer'], 'max_iter': [1000, 2000, 8000]}),\n       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97125193199381765"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n     verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1,\n 'dual': True,\n 'loss': 'squared_hinge',\n 'max_iter': 1000,\n 'multi_class': 'ovr',\n 'penalty': 'l2'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97404202719406674"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ourlsvc = LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
    "     penalty='l2', random_state=None, tol=0.0001, verbose=0).fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = ourlsvc.predict(X_test_vectorized)\n",
    "y_test_compare = y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LinearSVC with parameters from GridSearchCV')\n",
    "print('Accuracy: ', accuracy_score(y_test_compare, y_predict))\n",
    "print('f1: ', f1_score(y_test_compare, y_predict))\n",
    "print('Precision: ', precision_score(y_test_compare, y_predict))\n",
    "print('Recall: ', recall_score(y_test_compare, y_predict))\n",
    "print(classification_report(y_test_compare, y_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
